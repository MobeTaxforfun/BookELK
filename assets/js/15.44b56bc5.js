(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{452:function(a,t,s){"use strict";s.r(t);var r=s(65),e=Object(r.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"elasticsearch-中文分詞"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch-中文分詞"}},[a._v("#")]),a._v(" Elasticsearch 中文分詞")]),a._v(" "),s("p",[a._v("在 Elasticsearch 中，中文分詞是一個非常特殊的存在，中文幾乎是不可能靠著原生的分析器做到合理的斷詞，所以我們必須借助一些其他的 Plugin 來幫助我們處理中文斷詞的問題，以下紀錄一下安裝以及使用 IK Analysis 的過程")]),a._v(" "),s("p",[s("a",{attrs:{href:"https://github.com/medcl/elasticsearch-analysis-ik",target:"_blank",rel:"noopener noreferrer"}},[a._v("ik 分詞器"),s("OutboundLink")],1)]),a._v(" "),s("h2",{attrs:{id:"安裝-analysis-ik"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安裝-analysis-ik"}},[a._v("#")]),a._v(" 安裝 analysis-ik")]),a._v(" "),s("h2",{attrs:{id:"安裝-analysis-ik-繁中"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安裝-analysis-ik-繁中"}},[a._v("#")]),a._v(" 安裝  analysis-ik 繁中")]),a._v(" "),s("h2",{attrs:{id:"使用中文分詞"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用中文分詞"}},[a._v("#")]),a._v(" 使用中文分詞")]),a._v(" "),s("div",{staticClass:"language-JSON extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[a._v("PUT /ikanalyzertest/_mapping\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"properties"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"title"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"type"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"text"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"analyzer"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ik_max_word"')]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),s("div",{staticClass:"language-JSON extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[a._v("GET /_analyze/\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"analyzer"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"ik_smart"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[a._v('"text"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"憧憬是距離理解最遙遠的感情"')]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),s("h2",{attrs:{id:"字庫"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#字庫"}},[a._v("#")]),a._v(" 字庫")]),a._v(" "),s("h2",{attrs:{id:"結巴分詞"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#結巴分詞"}},[a._v("#")]),a._v(" 結巴分詞")]),a._v(" "),s("p",[a._v("待續")])])}),[],!1,null,null,null);t.default=e.exports}}]);