(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{451:function(t,s,n){t.exports=n.p+"assets/img/LogstashPipelinefolder.c7dd69a0.png"},452:function(t,s,n){t.exports=n.p+"assets/img/pm25test.f402b3ca.png"},475:function(t,s,n){"use strict";n.r(s);var a=n(65),e=Object(a.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"logstash-匯出-csv"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logstash-匯出-csv"}},[t._v("#")]),t._v(" Logstash 匯出 CSV")]),t._v(" "),a("p",[t._v("Logstash 擅長將各式的資料倒入 Elasticsearch 中，此篇記錄一下使用 Logstash 將 CSV 中的資料匯入 elasticsearch 中的過程")]),t._v(" "),a("p",[t._v("📘 Reference")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://www.elastic.co/guide/en/logstash/current/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("官方文件"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://www.kaggle.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("kaggle 數據建模和數據分析平台"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html#plugins-filters-mutate-convert",target:"_blank",rel:"noopener noreferrer"}},[t._v("Mutate filter plugin"),a("OutboundLink")],1)])]),t._v(" "),a("h2",{attrs:{id:"事前準備工作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#事前準備工作"}},[t._v("#")]),t._v(" 事前準備工作")]),t._v(" "),a("ul",[a("li",[t._v("先下載 Logstash 本文使用版本 logstash-7.17.1-windows 版本")]),t._v(" "),a("li",[t._v("找到一份 CSV 格式的資料，以"),a("code",[t._v(",")]),t._v("分隔資料，並有完整斷行")]),t._v(" "),a("li",[t._v("解壓縮後內容如下:\n"),a("img",{attrs:{src:n(451),alt:"logstash資料夾"}})]),t._v(" "),a("li",[t._v("在資料夾底下新增一個 "),a("code",[t._v("pipeline")]),t._v(" 的資料夾之後用來存放 pipeline 設定檔")]),t._v(" "),a("li",[t._v("以下為本文測試資料來至 Opendata pm2.5 csv 資料集結構如下\n"),a("img",{attrs:{src:n(452),alt:"測試資料"}})])]),t._v(" "),a("h2",{attrs:{id:"pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pipeline"}},[t._v("#")]),t._v(" Pipeline")]),t._v(" "),a("p",[t._v("準備好之後來編寫第一個 pipeline")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("pm25csv.conf\n在 "),a("code",[t._v("pipeline")]),t._v(" 這個資料夾底下新增一個 pm25csv.conf 文件，文件內容如下:")]),t._v(" "),a("div",{staticClass:"language-JSON extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[t._v("input "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    file "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        path => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:/DockerHub/Ref/Data/OpenData/pm25.csv"')]),t._v("\n        start_position => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beginning"')]),t._v("\n        sincedb_path=>"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:/DockerHub/Ref/Data/OpenData/pm25.log"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    stdin "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nfilter "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    csv "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        skip_header => "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n        separator => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),t._v("\n        columns => "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"device"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"town"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"types"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lat"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lon"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hum"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pm25"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"time"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\noutput "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    elasticsearch "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n        hosts => "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://localhost:9200/"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        index => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pm25-v1"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    stdout "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("ul",[a("li",[a("p",[t._v("Logstash Pipline 的三大要素分別是 input;filter;output")])]),t._v(" "),a("li",[a("p",[t._v("在 Input 的部分我們指定兩個 資料來源一個是 file ; 另一個是 stdin")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("input stdin")]),t._v(" 用來測試用的，下面會示範怎麼用")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("input file path")]),t._v(" 資料來源路徑")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("input file start_position")]),t._v(" 從甚麼位置開始讀取文件，Logstash預設是結束位置，就是每次都拿最後一筆，這種預設的模式適合用在讀 log 的環 境，因為若是 log 的話每次一筆新的日誌總是會添加在文件最後。而這邊我們導入的是整個 csv 文件所以讓 Logstash 從頭開始讀取設定為 "),a("code",[t._v("beginning")]),t._v(" 當讀取到最末時，Logstash 將自動切換為預設模式 "),a("code",[t._v("End")]),t._v(" 讀取最後一筆")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("input file sincedb_path")]),t._v(" 指定一個 log，這個 log 提供 Logstash "),a("code",[t._v("探針")]),t._v(" 紀錄最後一筆讀取資料的偏移量，若不指定會自動產生，若不想紀錄請設為 "),a("code",[t._v("null")]),t._v("，為了方便管理大多時候建議還是紀錄一下")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("filter csv skip_header")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("filter csv separator")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("filter csv columns")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("output elasticsearch hosts")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("output elasticsearch index")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("output stdout")])])])])])]),t._v(" "),a("p",[t._v("integer、integer_eu、float、float_eu、string、boolean")]),t._v(" "),a("h2",{attrs:{id:"mutate-filter-plugin"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mutate-filter-plugin"}},[t._v("#")]),t._v(" Mutate filter plugin")]),t._v(" "),a("div",{staticClass:"language-JSON extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[t._v("    input "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        file "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            path => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:/DockerHub/Ref/Data/OpenData/pm25.csv"')]),t._v("\n            start_position => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"beginning"')]),t._v("\n            sincedb_path=>"),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:/DockerHub/Ref/Data/OpenData/pm25.log"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        stdin "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    filter "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        csv "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            skip_header => "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n            separator => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),t._v("\n            columns => "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"device"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"town"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"types"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lat"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lon"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hum"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pm25"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"time"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        mutate "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            convert => "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),t._v(" => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"float"')]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hum"')]),t._v(" => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"float"')]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pm25"')]),t._v(" => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"float"')]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    output "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        elasticsearch "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n            hosts => "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://localhost:9200/"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            index => "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pm25-v1"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        stdout "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);